[ 
{ 
	"question": "An insurance company is creating an application that will perform analytics in near real-time on huge datasets in the terabyte range, and potentially even petabyte. The company is evaluating an AWS data storage option. Which AWS service will allow storage of petabyte-scale data and also allow fast complex queries over a large number of rows?", 	 
	"options": [
		"DynamoDB",
        "RDS",
        "Redshift",
        "ElastiCache"
	],
	"answers": ["C"]
},
{
	"question":"The engineering team at a company wants to use Amazon SQS to decouple components of the underlying application architecture. However, the team is concerned about the VPC-bound components accessing SQS over the public internet. As a solutions architect, which of the following solutions would you recommend to address this use-case?",
	"options":
	["Use Internet Gateway to access Amazon SQS",
	"Use VPN connection to access Amazon SQS",
	"Use Network Address Translation (NAT) instance to access Amazon SQS",
	"Use VPC endpoint to access Amazon SQS "],
	"answers":["D"],
	"explanation": "AWS customers can access Amazon Simple Queue Service (Amazon SQS) from their Amazon Virtual Private Cloud (Amazon VPC) using VPC endpoints, without using public IPs, and without needing to traverse the public internet. VPC endpoints for Amazon SQS are powered by AWS PrivateLink, a highly available, scalable technology that enables you to privately connect your VPC to supported AWS services."
},
{ 
	"question": "You have been evaluating the NACLs in your company. Currently, you are looking at the default network ACL. Which statement is true about NACLs?",
	"options": [
		"The default configuration of the default NACL is Deny, and the default configuration of a custom NACL is Deny.",
		"The default configuration of the default NACL is Allow, and the default configuration of a custom NACL is Allow.",
		"The default configuration of the default NACL is Deny, and the default configuration of a custom NACL is Allow.",
		"The default configuration of the default NACL is Allow, and the default configuration of a custom NACL is Deny."
	],
	"answers": ["D"]
},
{ 
	"question": "You work for an Australian company, who are currently being audited and need some compliance reports regarding your applications that are hosted on AWS. Specifically, they need a Australian Hosting Certification Framework - Strategic Certification certificate. You need to get this as quickly as possible. What should you do?",
	"options": [
		"Use AWS Certificate Manager to generate the certificate",
		"Use AWS Trusted Advisor to generate the report",
		"Use Amazon Detective to generate the report",
		"Use AWS Artifact to download the certificate"
	],
	"answers": ["D"]
},
{ 
	"question": "After being assigned to oversee the data storage within your organization, you begin looking at the monthly billing for S3. You notice that large amounts of data are sitting in S3, and after discussions with team members you find that a large amount of the data is historical data that needs to be kept for audit purposes. You detail the cost savings and get approval to move this data to Amazon Glacier for long-term storage. For what types of data is Glacier best suited?",
	"options": [
		"Archival data",
		"Infrequently accessed data",
		"Cached data",
		"Relational table data"
	],
	"answers": ["A", "B"]
},
{ 
	"question": "You are managing S3 buckets in your organization. This management of S3 extends to Amazon Glacier. For auditing purposes you would like to be informed if an object is restored to S3 from Glacier. What is the most efficient way you can do this?",
	"options": [
		"Create a CloudWatch Event for uploads to S3",
		"Configure S3 notifications for restore operations from Glacier",
		"Create a Lambda function which is triggered by restoration of object from Glacier to S3",
		"Create an SNS notification for any upload to S3"
	],
	"answers": ["B"]
},
{ 
	"question": "Your company has gotten back results from an audit. One of the mandates from the audit is that your application, which is hosted on EC2, must encrypt the data before writing this data to storage. It has been directed internally that you must have the ability to manage dedicated hardware security module instances to generate and store your encryption keys. Which service could you use to meet this requirement?",
	"options": [
		"AWS Security Token Service",
		"AWS CloudHSM",
		"Amazon EBS encryption",
		"AWS KMS"
	],
	"answers": ["B"]
},
{ 
	"question": "An organization of about 100 employees has performed the initial setup of users in IAM. All users except administrators have the same basic privileges. But now it has been determined that 50 employees will have extra restrictions on EC2. They will be unable to launch new instances or alter the state of existing instances. What will be the quickest way to implement these restrictions?",
	"options": [
		"Create an IAM Role for the restrictions. Attach it to the EC2 instances.",
		"Create the appropriate policy. With only 20 users, attach the policy to each user.",
		"Create the appropriate policy. Place the restricted users in the new policy.",
		"Create the appropriate policy. Create a new group for the restricted users. Place the restricted users in the new group and attach the policy to the group."
	],
	"answers": ["D"]
},
{ 
	"question": "A new startup company decides to use AWS to host their web application. They configure a VPC as well as two subnets within the VPC. They also attach an internet gateway to the VPC. In the first subnet, they create the EC2 instance which will host their web application. They finish the configuration by making the application accessible from the Internet. The second subnet hosts their database and they don't want the database accessible from the Internet. Which statement best describes this scenario?",
	"options": [
		"The web server is in a public subnet, and the database server is in a private subnet. The public subnet has a route to the internet gateway in the route table.",
		"The web server is in a private subnet, and the database server is in a public subnet. The public subnet has a route to the internet gateway in the route table.",
		"The web server is in a public subnet, and the database server is in a public subnet. The public subnet has a route to the internet gateway in the route table.",
		"The web server is in a private subnet, and the database server is in a private subnet. A third subnet has a route to the Internet Gateway, which allows internet access."
	],
	"answers": ["A"]
},
{ 
	"question": "A company has created a mobile application that is hugely popular. The initial plan was to give each user login credentials to the application. But due to the volume of users, this idea has become impractical. What service can you use to allow outside users to login through a third party such as Facebook, Amazon, Google or Apple?",
	"options": [
		"Amazon Cognito",
		"AWS cross account access",
		"AWS IAM",
		"Google Authenticator"
	],
	"answers": ["A"]
},
{ 
	"question": "You have been given an assignment to configure Network ACLs in your VPC. Before configuring the NACLs, you need to understand how the NACLs are evaluated. How are NACL rules evaluated?",
	"options": [
		"All NACL rules that you configure are evaluated before traffic is passed through.",
		"NACL rules are evaluated by rule number from highest to lowest, and executed immediately when a matching rule is found.",
		"NACL rules are evaluated by rule number from highest to lowest, and all are evaluated before traffic is passed through.",
		"NACL rules are evaluated by rule number from lowest to highest and executed immediately when a matching rule is found."
	],
	"answers": ["D"]
},
{ 
	"question": "You have been evaluating the NACLs in your company. Most of the NACLs are configured the same:<code>100 All Traffic Allow<br>200 All Traffic Deny<br>* All Traffic Deny</code>If a request comes in, how will it be evaluated?",
	"options": [
		"The highest numbered rule will be used, a deny.",
		"All rules will be evaluated and the end result will be Deny.",
		"The request will be allowed.",
		"The default will deny traffic."
	],
	"answers": ["C"]
},
{ 
	"question": "You are working for a startup company with a small number of employees. The company expects rapid growth and you have been assigned to configure existing users and onboard new users with IAM privileges and logins. You intend to create IAM groups for the company departments and add new users to the appropriate group when you onboard them. You begin creating policies to assign permissions and attach them to the appropriate group. What is the best practice when giving users permissions in IAM policies?",
	"options": [
		"Use the principle of least privilege.",
		"Use the principle of top-down privilege.",
		"Create a policy for each department head granting root access.",
		"Grant all permissions to each AWS service the user will work with."
	],
	"answers": ["A"]
},
{ 
	"question": " You work for a consulting company, which is currently undergoing both a financial and technical audit. You have been asked by the auditors to produce regular reports in regards to your PCI compliance. You need to produce this as fast and as efficiently as possible. Which AWS service should you consider using?",
	"options": [
		"Amazon Audit Automation",
		"AWS Security Hub",
		"Amazon Detective",
		"AWS Audit Manager"
	],
	"answers": ["D"]
},
{ 
	"question": "Your company needs to deploy an application in the company AWS account. The application will reside on EC2 instances in an Auto Scaling Group fronted by an Application Load Balancer. The company has been using Elastic Beanstalk to deploy the application due to limited AWS experience within the organization. The application now needs upgrades and a small team of subcontractors have been hired to perform these upgrades. Which web service can be used to provide users that you authenticate with short-term security credentials that can control access to your AWS resources?",
	"options": [
		"IAM user accounts",
		"AWS STS",
		"IAM Group",
		"AWS SSO"
	],
	"answers": ["B"]
},
{ 
	"question": "You are evaluating the security setting within the main company VPC. There are several NACLs and security groups to evaluate and possibly edit. What is true regarding NACLs and security groups?",
	"options": [
		"Network ACLs are stateless, and security groups are stateful.",
		"Network ACLs and security groups are both stateless.",
		"Network ACLs and security groups are both stateful.",
		"Network ACLs are stateful, and security groups are stateless."
	],
	"answers": ["A"]
},
{ 
	"question": "A small startup company has multiple departments with small teams representing each department. They have hired you to configure Identity and Access Management in their AWS account. The team expects to grow rapidly, and promote from within which could mean promoted team members switching over to a new team fairly often. How can you configure IAM to prepare for this type of growth?",
	"options": [
		"Create the user accounts, create a group for each department, create and attach an appropriate role to each group, and place each user account into their department's group. When new team members are onboarded, create their account and put them in the appropriate group. If an existing team member changes departments, move their account to their new IAM group.",
		"Create the user accounts, create a group for each department, create and attach an appropriate policy to each group, and place each user account into their department's group. When new team members are onboarded, create their account and put them in the appropriate group. If an existing team member changes departments, delete their account, create a new account and put the account in the appropriate group.",
		"Create the user accounts, create a group for each department, create and attach an appropriate policy to each group, and place each user account into their department's group. When new team members are onboarded, create their account and put them in the appropriate group. If an existing team member changes departments, move their account to their new IAM group.",
		"Create the user accounts, create a role for each department, create and attach an appropriate policy to each role, and place each user account into their department's role. When new team members are onboarded, create their account and put them in the appropriate role. If an existing team member changes departments, move their account to their new IAM group."
	],
	"answers": ["C"]
},
{ 
	"question": "Several S3 Buckets have been deleted and a few EC2 instances have been terminated. Which AWS service can you use to determine who took these actions?",
	"options": [
		"AWS CloudWatch",
		"AWS CloudTrail",
		"AWS Inspector",
		"Trusted Advisor"
	],
	"answers": ["B"]
},
{ 
	"question": "A consultant is hired by a small company to configure an AWS environment. The consultant begins working with the VPC and launching EC2 instances within the VPC. The initial instances will be placed in a public subnet. The consultant begins to create security groups. The consultant has launched several instances, created security groups, and has associated security groups with instances. The consultant wants to change the security groups that are associated with the instance. Which statement is true?",
	"options": [
		"You can't change the security groups for an instance when the instance is in the running or stopped state.",
		"You can't change security groups. Create a new instance and attach the desired security groups.",
		"You can change the security groups for an instance when the instance is in the running or stopped state.",
		"You can change the security groups for an instance when the instance is in the pending or stopped state."
	],
	"answers": ["C"]
},
{ 
	"question": "You have been put in charge of S3 buckets for your company. The buckets are separated based on the type of data they are holding and the level of security required for that data. You have several buckets that have data you want to safeguard from accidental deletion. Which configuration will meet this requirement?",
	"options": [
		"Archive sensitive data to Amazon Glacier.",
		"Enable versioning on the bucket and multi-factor authentication delete as well.",
		"Signed URLs to all users to access the bucket.",
		"Configure cross-account access with an IAM Role prohibiting object deletion in the bucket."
	],
	"answers": ["B"]
},
{ 
	"question": "A financial institution has an application that produces huge amounts of actuary data, which is ultimately expected to be in the terabyte range. There is a need to run complex analytic queries against terabytes of structured data, using sophisticated query optimization, columnar storage on high-performance storage, and massively parallel query execution. Which service will best meet this requirement?",
	"options": [
		"Redshift",
		"RDS",
		"DynamoDB",
		"Elasticache"
	],
	"answers": ["A"]
},
{ 
	"question": "Currently, you are employed as a solutions architect for a large international shipping company. The company is undergoing an IT transformation and they want to create an immutable database, where they can track packages as they are sent around the world. They will need to track what boxes they go in, what trucks they are sent in, and what aircraft or sea containers they are shipped in. The database needs to be immutable and cryptographically verifiable, and they would like to leverage the AWS cloud to achieve this. What database technology would best suit this requirement?",
	"options": [
		"Amazon Quantum Ledger Database (QLDB)",
		"Aurora",
		"RDS",
		"Neptune"
	],
	"answers": ["A"]
},
{ 
	"question": "You are designing a new application for a social media gaming company and they want to be able to use people’s facebook account to login and to sign up to the new app. They’ve asked that you use Cognito to achieve this. However, management wants to know the steps involved for user authentication. Which of the steps below is the correct order to authenticate with Cognito?",
	"options": [
		"Step 1 - Exchange tokens and get AWS credentials. Step 2 - Authenticate and get tokens. Step 3 - Access AWS services using credentials.",
		"Step 1 - Access AWS services using credentials. Step 2 - Exchange tokens and get AWS credentials. Step 3 - Authenticate and get tokens.",
		"Step 1 - Exchange tokens and get AWS credentials. Step 2 - Access AWS services using credentials. Step 3 - Authenticate and get tokens.",
		"Step 1 - Authenticate and get tokens. Step 2 - Exchange tokens and get AWS credentials. Step 3 - Access AWS services using credentials."
	],
	"answers": ["D"]
},
{ 
	"question": "You have a typical architecture for an Application Load Balancer fronting an Auto Scaling group of EC2 instances, backed by an RDS MySQL database. Your Application Load Balancer is performing health checks on the EC2 instances. What actions will be taken if an instance fails these health checks?",
	"options": [
		"The instance is terminated by the ALB.",
		"The instance is replaced by the ALB.",
		"The ALB stops sending traffic to the instance.",
		"The ALB notifies the Auto Scaling group that the instance is down."
	],
	"answers": ["C"]
},
{ 
	"question": "The AWS team in a large company is spending a lot of time monitoring EC2 instances and maintenance when the instances report health check failures. How can you most efficiently automate this monitoring and repair?",
	"options": [
		"Create a Lambda function which can be triggered by a failed instance health check. Have the Lambda function deploy a CloudFormation template which can perform the creation of a new instance.",
		"Create a cron job which monitors the instances periodically and starts a new instance if a health check has failed.",
		"Create a Lambda function which can be triggered by a failed instance health check. Have the Lambda function destroy the instance and spin up a new instance.",
		"Create an Amazon CloudWatch alarm that monitors an Amazon EC2 instance and automatically reboots the instance if a health check fails."
	],
	"answers": ["D"]
},
{ 
	"question": "An application team has decided to leverage AWS for their application infrastructure. The application performs proprietary, internal processes that other business applications utilize for their daily workloads. It is built with Apache Kafka to handle real-time streaming, which virtual machines running the application in docker containers consume the data from. The team wants to leverage services that provide less overhead but also cause the least amount of disruption to coding and deployments. Which combination of AWS services would best meet the requirements?",
	"options": [
		"Amazon MSK",
		"Amazon SNS",
		"AWS Lambda",
		"Amazon ECS Fargate",
		"Amazon MQ",
		"Amazon Kinesis Data Streams"
	],
	"answers": ["A", "D"]
},
{ 
	"question": "You work for an online retailer where any downtime at all can cause a significant loss of revenue. You have architected your application to be deployed on an Auto Scaling Group of EC2 instances behind a load balancer. You have configured and deployed these resources using a CloudFormation template. The Auto Scaling Group is configured with default settings and a simple CPU utilization scaling policy. You have also set up multiple Availability Zones for high availability. The load balancer does health checks against an HTML file generated by script. When you begin performing load testing on your application and notice in CloudWatch that the load balancer is not sending traffic to one of your EC2 instances. What could be the problem?",
	"options": [
		"The EC2 instance has failed the load balancer health check.",
		"The EC2 instance has failed EC2 status checks.",
		"You are load testing at a moderate traffic level and not all instances are needed.",
		"The instance has not been registered with CloudWatch."
	],
	"answers": ["A"]
},
{
	"question":"Jennifer is a cloud engineer for her application team. The application leverages several third-party SaaS vendors to complete their workflows within the application. Currently, the team uses numerous AWS Lambda functions for each SaaS vendor that run daily to connect to the configured vendor. The functions initiate a transfer of data files, ranging from one megabyte up to 80 gibibytes in size. These data files are stored in an Amazon S3 bucket and then referenced by the application itself. The data transfer routinely fails due to execution timeout limits in the Lambda functions, and the team wants to find a simpler and less error-prone way of transferring the required data. Which solution or AWS service could be the best fit for their solution?",
	"options":
	["Increase the Lambda function timeouts to one hour",
	"Amazon EKS with Auto Scaling",
	"Amazon AppFlow",
	"Amazon EC2 Auto Scaling Groups"],
	"answers":["C"]
},
{
	"question":"You have taken over management of several instances in the company AWS environment. You want to quickly review scripts used to bootstrap the instances at runtime. A URL command can be used to do this. What can you append to the URL http://169.254.169.254/latest/ to retrieve this data?",
	"options":
	["user-data/",
	"instance-data/",
	"instance-demographic-data/",
	"meta-data/"],
	"answers":["A"]
},
{
	"question":"Your company has performed a Disaster Recovery drill which failed to meet the Recovery Time Objective (RTO) desired by executive management. The failure was due in large part to the amount of time taken to restore proper functioning on the database side. You have given management a recommendation of implementing synchronous data replication for the RDS database to help meet the RTO. Which of these options can perform synchronous data replication in RDS?",
	"options":
	["AWS Database Migration Service",
	"RDS Multi-AZ",
	"DAX",
	"Read replicas"],
	"answers":["B"]
},
{
	"question":"A new startup is considering the advantages of using Amazon DynamoDB versus a traditional relational database in AWS RDS. The NoSQL nature of DynamoDB presents a small learning curve to the team members who all have experience with traditional databases. The company will have multiple databases, and the decision will be made on a case-by-case basis. Which of the following use cases would favor Amazon DynamoDB?",
	"options":
	["Online analytical processing (OLAP)/data warehouse implementations",
	"High-performance reads and writes for online transaction processing (OLTP) workloads",
	"Strong referential integrity between tables",
	"Managing web session data",
	"Storing metadata for S3 objects",
	"Storing binary large object (BLOB) data"],
	"answers":["B", "D", "E"]
},
{
	"question":"You are working for a large financial institution and preparing for disaster recovery and upcoming DR drills. A key component in the DR plan will be the database instances and their data. An aggressive Recovery Time Objective (RTO) dictates that the database needs to be synchronously replicated. Which configuration can meet this requirement?",
	"options":
	["RDS read replicas",
	"RDS Multi-AZ",
	"AWS Lambda triggers a CloudFormation template launch in another Region.",
	"RDS Multi-Region"],
	"answers":["B"]
},
{
	"question":"An online retailer currently runs their application within AWS. Currently, everything is running on Amazon EC2 instances, including all application software. The application is well-written and completes order processes following a specific workflow logic order. The online retailer has begun to explore shifting their entire code base to AWS Lambda for each compute-based portion of the workflow, but they are not sure how best to interconnect the functions. There are three major requirements that need to be met. The first is that they need to implement a 20-minute wait period between certain functions in the application code and process. The second is they want to be able to conditionally handle a few different known scenarios that may occur during the order processing. The last requirement is to have an auditable workflow history. Which AWS service is the best fit for their workflow orchestration needs that has the least operational overhead and is the most cost-efficient?",
	"options":
	["Amazon EKS with Amazon RDS",
	"AWS Lambda with Amazon S3",
	"AWS Step Functions with AWS Lambda",
	"AWS Lambda with Amazon SNS"],
	"answers":["C"]
},
{
	"question":"You have been hired as a Solutions Architect for a company that pairs photos with related story narratives in PDF format. The company needs to be able to store files in several different formats, such as PDF, JPG, PNG, Word, and several others. This storage needs to be highly durable. Which storage type will best meet this requirement?",
	"options":
	["Amazon RDS",
	"S3",
	"DynamoDB",
	"EC2 instance store"],
	"answers":["B"]
},
{
	"question":"Your company has decided to migrate a SQL Server database to a newly-created AWS account. Which service can be used to migrate the database?",
	"options":
	["Database Migration Service",
	"Elasticache",
	"AWS RDS",
	"DynamoDB"],
	"answers":["A"]
},
{
	"question":"Due to strict compliance requirements, your company cannot leverage AWS cloud for hosting their Kubernetes clusters, nor for managing the clusters. However, they do want to try to follow the established best practices and processes that the Amazon EKS service has implemented. How can your company achieve this while running entirely on-premises?",
	"options":
	["Run Amazon EKS.",
	"This cannot be done.",
	"Run Amazon ECS anywhere.",
	"Run the clusters on-premises using Amazon EKS Distro."],
	"answers":["D"]
},
{
	"question":"A financial tech company has decided to begin migrating their applications to the AWS cloud. Currently, they host their entire application using several self-managed Kubernetes clusters. One of their major concerns during this migration is monitoring and collecting system metrics due to the very large-scale deployments that are in place. Your Chief Technology Officer wants to avoid using AWS-proprietary technology-based monitoring services and instead leverage existing, well-known, open-source applications to help meet the monitoring requirements. Which combination of the following AWS services would best fit the company requirements while minimizing operational overhead?",
	"options":
	["AWS Managed Service for Prometheus",
	"AWS Managed Grafana",
	"Grafana on Auto Scaling EC2 Instances",
	"Prometheus on Auto Scaling EC2 Instances",
	"AWS Config"],
	"answers":["A", "B"]
},
{
	"question":"A data company has implemented a subscription service for storing video files. There are two levels of subscription: personal and professional use. The personal users can upload a total of 5 GB of data, and professional users can upload as much as 5 TB of data. The application can upload files of size up to 1 TB to an S3 Bucket. What is the best way to upload files of this size?",
	"options":
	["Multipart upload",
	"AWS Snowball",
	"Single-part Upload",
	"AWS SnowMobile"],
	"answers":["A"]
},
{
	"question":"A team of architects is designing a new AWS environment for a company which wants to migrate to the Cloud. The architects are considering the use of EC2 instances with instance store volumes. The architects realize that the data on the instance store volumes are ephemeral. Which action will not cause the data to be deleted on an instance store volume?",
	"options":
	["Hardware disk failure.",
	"Reboot",
	"Instance is stopped",
	"The underlying disk drive fails."],
	"answers":["B"]
},
{
	"question":"You work for a large healthcare provider as an AWS lead architect. There is a need to collect data in real-time from devices throughout the organization. The data will include log and event data from sources such as servers, desktops, and mobile devices. The data initially captured will be technical device data, but the goal is to expand the effort to collecting clinical data in real-time from handheld devices used by nurses and doctors. Which AWS service best meets this requirement?",
	"options":
	["AWS Lambda",
	"Kinesis Data Streams",
	"Kinesis Video Streams",
	"AWS Redshift"],
	"answers":["B"]
},
{
	"question":"A gaming company is designing several new games which focus heavily on player-game interaction. The player makes a certain move and the game has to react very quickly to change the environment based on that move and to present the next decision for the player in real-time. A tool is needed to continuously collect data about player-game interactions and feed the data into the gaming platform in real-time. Which AWS service can best meet this need?",
	"options":
	["AWS Lambda",
	"Kinesis Data Analytics",
	"Kinesis Data Streams",
	"AWS IoT"],
	"answers":["C"]
},
{
	"question":"You work for a large online education company that teaches IT using pre-recorded videos. You have converted their online videos into text to be accessible for the hearing impaired. They now want to convert the transcribed text into other languages using artificial intelligence and machine learning. Which AWS service should they use?",
	"options":
	["Amazon Transcribe",
	"Amazon Translate",
	"Amazon Comprehend",
	"Amazon Rekognition"],
	"answers":["B"]
},
{
	"question":"Your application team stores critical data within a third-party SaaS cloud vendor. The data comes from an internal application that runs on Amazon ECS Fargate, which then stores the data within Amazon S3 in a proprietary format. Currently, AWS Lambda functions are triggered via Amazon S3 event notifications to trigger the transfer of data to an SaaS application. Due to resource and time limits, you are exploring other means of completing this workflow of transferring data from AWS to the SaaS solution. Which AWS service offers the most efficiency and has the least operational overhead?",
	"options":
	["Amazon EKS",
	"AWS Step Function Fargate Capacity",
	"Amazon EventBridge",
	"Amazon AppFlow"],
	"answers":["D"]
},
{
	"question":"A small startup company has begun using AWS for all of its IT infrastructure. The company has one AWS Solutions Architect and the demands for their time are overwhelming. The software team has been given permission to deploy their Python and PHP applications on their own. They would like to deploy these applications without having to worry about the underlying infrastructure. Which AWS service would they use for deployments?",
	"options":
	["CloudFormation",
	"CloudFront",
	"Elastic Beanstalk",
	"CodeDeploy"],
	"answers":["C"]
},
{
	"question":"Your team has provisioned Auto Scaling groups in a single Region. The Auto Scaling groups, at max capacity, would total 40 EC2 On-Demand Instances between them. However, you notice that the Auto Scaling groups will only scale out to a portion of that number of instances at any one time. What could be the problem?",
	"options":
	["You can have only 20 instances per Availability Zone.",
	"You can have only 20 instances per Region. This is a hard limit.",
	"There is a vCPU-based On-Demand Instance limit per Region.",
	"The associated load balancer can serve only 20 instances at one time."],
	"answers":["C"]
},
{
	"question":"You work for an advertising company that has a real-time bidding application. You are also using CloudFront on the front end to accommodate a worldwide user base. Your users begin complaining about response times and pauses in real-time bidding. What is the best service that can be used to reduce DynamoDB response times by an order of magnitude (milliseconds to microseconds)?",
	"options":
	["Amazon DynamoDB Accelerator (DAX)",
	"DynamoDB Auto Scaling",
	"ElastiCache",
	"CloudFront Edge Caches"],
	"answers":["A"]
},
{
	"question":"Your company is in the process of creating a multi-region disaster recovery solution for your database, and you have been tasked to implement it. The required recovery time objective (RTO) is 1 hour, and the Recovery Point Objective (RPO) is 15 minutes. What steps can you take to ensure these thresholds are met?",
	"options":
	["Take EBS snapshots of the required EC2 instances nightly. In the event of a disaster, restore the snapshots to another region.",
	"Use Redshift to host your database. Enable \"multi-region\" failover with Redshift. In the event of a failure, do nothing, as Redshift will handle it for you.",
	"Use RDS to host your database. Enable the Multi-AZ option for your database. In the event of a failure, cut over to the secondary database.",
	"Use RDS to host your database. Create a cross-region read replica of your database. In the event of a failure, promote the read replica to be a standalone database. Send new reads and writes to this database."],
	"answers":["D"]
},
{
	"question":"You are designing an architecture which will house an Auto Scaling Group of EC2 instances. The application hosted on the instances is expected to be extremely popular. Forecasts for traffic to this site expect very high traffic and you will need a load balancer to handle tens of millions of requests per second while maintaining high throughput at ultra low latency. You need to select the type of load balancer to front your Auto Scaling Group to meet this high traffic requirement. Which load balancer will you select?",
	"options":
	["You will select a Network Load Balancer to meet this requirement.",
	"You will need a Classic Load Balancer to meet this requirement.",
	"You will need an Application Load Balancer to meet this requirement.",
	"All the AWS load balancers meet the requirement and perform the same."],
	"answers":["A"]
},
{
	"question":"You have just started working at a company that is migrating from a physical data center into AWS. Currently, you have 25 TB of data that needs to be moved to an S3 bucket. Your company has just finished setting up a 1 GB Direct Connect drop, but you will not have a VPN up and running for 30 days. This data needs to be encrypted during transit and at rest and must be uploaded to the S3 bucket within 21 days. What is the best way to meet these requirements?",
	"options":
	["Upload the data using Direct Connect.",
	"Use a Snowball device to transmit the data.",
	"Order a Snowcone device to transmit the data.",
	"Upload the data to S3 using your public internet connection."],
	"answers":["B"]
},
{
	"question":"A Solutions Architect has been assigned the task of helping the company development optimize the performance of their web application. End users have been complaining about slow response times. The Solutions Architect has determined that improvements can be realized by adding ElastiCache to the solution. What can ElastiCache do to improve performance?",
	"options":
	["Offload some of the write traffic to the database.",
	"Cache frequently accessed data in-memory.",
	"Delivers up to 10x performance improvement from milliseconds to microseconds or even at millions of requests per second.",
	"Queue up requests and allow the processor time to catch-up."],
	"answers":["B"]
},
{
	"question":"A software company has developed a social gaming application that leverages EC2 web servers with Amazon DynamoDB to store player data, session history, and leaderboards for a huge number of concurrent users. The DynamoDB table has pre-configured read and write capacity units. Users have been reporting slowdown issues, and an analysis has revealed that the application requires response times in microseconds for optimal performance. What step can you take to enable this application to handle read-heavy or bursty workloads, while delivering the fastest possible response time for eventually consistent read operations?",
	"options":
	["Add a load balancer in front of the EC2 web servers to decouple your application requests synchronously, improving performance for read-heavy and bursty workloads.",
	"Deploy Amazon CloudFront to your architecture, so you can cache common Amazon DynamoDB queries and reduce response time to microseconds.",
	"Configure Amazon SQS to queue requests that could be lost and improve the application response time.",
	"Implement in-memory acceleration with DynamoDB Accelerator (DAX)."],
	"answers":["D"]
},
{
	"question":"You work for a large online education company that teaches IT using pre-recorded videos. They want to make their website available to the hearing impaired and need to find a way to convert their videos and audio into speech that they can then display as subtitles. Which AWS service should they use?",
	"options":
	["Amazon Comprehend",
	"Amazon Rekognition",
	"Amazon Transcribe",
	"Amazon Translate"],
	"answers":["C"]
},
{
	"question":"A company is going to use several EC2 instances to host various reference applications. The applications are expected to receive steady and relatively low traffic. These applications are expected to run for 3 years, at which time the applications will be evaluated for upgrade. What type of EC2 will meet this requirement considering cost as an additional factor?",
	"options":
	["Dedicated Hosts",
	"On-Demand",
	"Reserved",
	"Spot"],
	"answers":["C"]
},
{
	"question":"After an IT Steering Committee meeting, you have been put in charge of configuring a hybrid environment for the company’s compute resources. You weigh the pros and cons of various technologies based on the requirements you are given. The decision you make is to go with Direct Connect. Which option best describes the features Direct Connect provides?",
	"options":
	["A private, dedicated network connection between your facilities and AWS",
	"A cost-effective, private network connection that bypasses the internet",
	"A connection between on-premises and VPC, using secure and private connection with IPsec and TLS",
	"A network connection between two VPCs that can route traffic using IPv4 or IPv6"],
	"answers":["A"]
},
{
	"question":"You have recently migrated your small company to AWS and are looking for some general best practice guidance within the platform. Which AWS service can help you optimize your AWS environment by giving recommendations to reduce cost, increase performance, and improve security?",
	"options":
	["AWS Trusted Advisor",
	"AWS Inspector",
	"AWS Optimizations",
	"AWS Organizations"],
	"answers":["A"]
},
{
	"question":"You are managing data storage for your company, and there are many EBS volumes. Your management team has given you some new requirements. Certain metrics on the EBS volumes need to be monitored, and the database team needs to be notified by email when certain metric thresholds are exceeded. Which AWS services can be configured to meet these requirements?",
	"options":
	["SES",
	"SQS",
	"SNS",
	"CloudWatch",
	"SWF"],
	"answers":["C", "D"]
},
{
	"question":"Your company has a multi-account AWS environment with over 100 accounts. Each account belongs to a specific application team within the company, and they all fall within the same consolidated billing family. The company has just received funding for the next two years, but they are unsure about anything beyond that. With this in mind, they plan on aggressively deploying applications to AWS during the two years. Recently, there was a massive spike in unplanned Amazon EC2 and AWS Lambda costs, causing significant financial stress. What can an organization administrator do to maximize savings for the entire organization for this first year?",
	"options":
	["Purchase a three-year All Upfront Compute Savings Plan.",
	"Purchase a three-year All Upfront EC2 Instance Savings Plan.",
	"Purchase a one-year All Upfront EC2 Instance Savings Plan.",
	"Purchase a one-year All Upfront Compute Savings Plan."],
	"answers":["D"]
},
{
	"question":"Your team owns three separate AWS accounts: one for production, one for staging, and one for development. Recently, there has been a push from the CEO to begin breaking down costs to the most comprehensive, detailed level. In addition to this level of detail, the team needs to store daily comma-separated value (CSV) reports in Amazon S3 for ingestion into the company’s internal analytics tooling. What would be the most efficient solution for this scenario?",
	"options":
	["Use AWS Cost and Usage Reports to generate reports with the required amount of detail. Set up Amazon EventBridge (Amazon CloudWatch Events) to trigger a rule to create and then export CSV reports daily to a centralized Amazon S3 bucket.",
	"Use AWS Budgets to alert and generate reports on current spend, and use AWS Fargate to pull data, generate CSV reports, and then push them to Amazon S3.",
	"Use AWS Budgets to alert and generate reports, and use AWS Lambda to pull data, generate CSV reports, and then push them to Amazon S3.",
	"Use AWS Cost and Usage Reports to generate reports, and have it export CSV reports daily to a centralized Amazon S3 bucket."],
	"answers":["D"]
},
{
	"question":"Your company needs to shift an application to the cloud. You are looking for a solution to collect, process, gain immediate insight, and then transfer the application data to AWS. Part of this effort also includes moving a large data warehouse into AWS. The warehouse is 50TB, and it would take over a month to migrate the data using the current bandwidth available. What is the best option available to perform this one time migration considering both cost and performance aspects?",
	"options":
	["AWS SnowMobile",
	"AWS Snowball Edge",
	"AWS Direct Connect",
	"AWS VPN"],
	"answers":["B"]
},
{
	"question":"You are working in a large healthcare facility which uses EBS volumes on most of the EC2 instances. The CFO has approached you about some cost savings and it has been decided that some of the EC2 instances and EBS volumes would be deleted. What step can be taken to preserve the data on the EBS volumes and keep the data available on short notice?",
	"options":
	["Archive the data to Glacier.",
	"Store the data in CloudFormation user data.",
	"Move the data to Amazon S3.",
	"Take point-in-time snapshots of your Amazon EBS volumes."],
	"answers":["D"]
},
{
	"question":"You have joined a newly formed software company as a Solutions Architect. It is a small company, and you are the only employee with AWS experience. The owner has asked for your recommendations to ensure that the AWS resources are deployed to proactively remain within budget. Which AWS service can you use to help ensure you don’t have cost overruns for your AWS resources?",
	"options":
	["AWS Budgets",
	"Billing and Cost Management",
	"Cost Explorer",
	"Inspector"],
	"answers":["A"]
},
{
	"question":"You work for a Defense contracting company. The company develops software applications which perform intensive calculations in the area of Mechanical Engineering related to metals for ship building. You have a 3-year contract and decide to purchase reserved EC2 instances for a 3-year duration. You are informed that the particular program has been cancelled abruptly and negotiations have brought the contract to an amicable conclusion one year early. What can you do to stop incurring charges and save money on the EC2 instances?",
	"options":
	["Write AWS and ask to terminate the contract.",
	"Change the instance states from running to stopped.",
	"Sell the reserved instances on the Reserved Instance Marketplace.",
	"Convert the instances to Spot Instances and allow them to go away through attrition."],
	"answers":["C"]
},
{
	"question":"A testing team is using a group of EC2 instances to run batch, automated tests on an application. The tests run overnight, but don’t take all night. The instances sit idle for long periods of time and accrue unnecessary charges. What can you do to stop these instances when they are idle for long periods?",
	"options":
	["Write a cron job which queries the instance status. Also write a Lambda function which can be triggered upon a certain status and stop the instance.",
	"Write a Python script which queries the instance status. Also write a Lambda function which can be triggered upon a certain status and stop the instance.",
	"Write a cron job which queries the instance status. If a certain status is met, have the cron job kick off CloudFormation to terminate the existing instance, and create a new instance from a template.",
	"You can create a CloudWatch alarm that is triggered when the average CPU utilization percentage has been lower than 10 percent for 4 hours, and stops the instance."],
	"answers":["D"]
},
{
	"question":"After an IT Steering Committee meeting, you have been put in charge of configuring a hybrid environment for the company’s compute resources. You weigh the pros and cons of various technologies, such as VPN and Direct Connect, and based on the requirements you have decided to configure a VPN connection. What features and advantages can a VPN connection provide?",
	"options":
	["It provides a cost-effective, private network connection that bypasses the internet.",
	"It provides a connection between an on-premises network and a VPC, using a secure and private connection with IPsec and TLS.",
	"It provides a network connection between two VPCs that can route traffic using IPv4 or IPv6.",
	"It provides a private, dedicated network connection between an on-premises network and the VPC."],
	"answers":["B"]
},
{
	"question":"A company needs to deploy EC2 instances to handle overnight batch processing. This includes media transcoding and some voice to text transcription. This is not high priority work, and it is OK if these batch runs get interrupted. What is the best EC2 instance purchasing option for this work?",
	"options":
	["On-Demand",
	"Spot",
	"Reserved",
	"Dedicated Hosts"],
	"answers":["B"]
},
{
	"question":"A media company runs a photo-sharing web application that is accessed across three different countries. The application is deployed on several Amazon EC2 instances running behind an Application Load Balancer. With new government regulations, the company has been asked to block access from two countries and allow access only from the home country of the company.<br>Which configuration should be used to meet this changed requirement?",
	"options":
	["Configure the security group on the Application Load Balancer",
	"Configure AWS WAF on the Application Load Balancer in a VPC",
	"Use Geo Restriction feature of Amazon CloudFront in a VPC",
	"Configure the security group for the EC2 instances"],
	"answers":["B"]
},
{
	"question":"A financial services company recently launched an initiative to improve the security of its AWS resources and it had enabled AWS Shield Advanced across multiple AWS accounts owned by the company. Upon analysis, the company has found that the costs incurred are much higher than expected.<br>Which of the following would you attribute as the underlying reason for the unexpectedly high costs for AWS Shield Advanced service?",
	"options":
	["Savings Plans has not been enabled for the AWS Shield Advanced service across all the AWS accounts",
	"AWS Shield Advanced also covers AWS Shield Standard plan, thereby resulting in increased costs",
	"AWS Shield Advanced is being used for custom servers, that are not part of AWS Cloud, thereby resulting in increased costs",
	"Consolidated billing has not been enabled. All the AWS accounts should fall under a single consolidated billing for the monthly fee to be charged only once"],
	"answers":["D"]
},{
	"question":"An audit department generates and accesses the audit reports only twice in a financial year. The department uses AWS Step Functions to orchestrate the report creating process that has failover and retry scenarios built into the solution. The underlying data to create these audit reports is stored on S3, runs into hundreds of Terabytes and should be available with millisecond latency.<br>As a solutions architect, which is the MOST cost-effective storage class that you would recommend to be used for this use-case?",
	"options":
	["Amazon S3 Intelligent-Tiering (S3 Intelligent-Tiering)",
	"Amazon S3 Glacier Deep Archive",
	"Amazon S3 Standard",
	"Amazon S3 Standard-Infrequent Access (S3 Standard-IA)"],
	"answers":["D"]
},
{
	"question":"The IT department at a consulting firm is conducting a training workshop for new developers. As part of an evaluation exercise on Amazon S3, the new developers were asked to identify the invalid storage class lifecycle transitions for objects stored on S3.<br>Can you spot the INVALID lifecycle transitions from the options below? (Select two)",
	"options":
	["S3 One Zone-IA => S3 Standard-IA",
	"S3 Standard-IA => S3 Intelligent-Tiering",
	"S3 Intelligent-Tiering => S3 Standard",
	"S3 Standard => S3 Intelligent-Tiering",
	"S3 Standard-IA => S3 One Zone-IA"],
	"answers":["A", "C"]
},
{
	"question":"A geological research agency maintains the seismological data for the last 100 years. The data has a velocity of 1GB per minute. You would like to store the data with only the most relevant attributes to build a predictive model for earthquakes.<br>What AWS services would you use to build the most cost-effective solution with the LEAST amount of infrastructure maintenance?",
	"options":
	["Ingest the data in Kinesis Data Firehose and use an intermediary Lambda function to filter and transform the incoming stream before the output is dumped on S3",
	"Ingest the data in Kinesis Data Analytics and use SQL queries to filter and transform the data before writing to S3",
	"Ingest the data in Kinesis Data Streams and use an intermediary Lambda function to filter and transform the incoming stream before the output is dumped on S3",
	"Ingest the data in a Spark Streaming Cluster on EMR use Spark Streaming transformations before writing to S3"],
	"answers":["A"]
}
]